{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4632e058-d1f7-48bf-8ec9-9abfd6a0d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q1.\n",
    "\n",
    "To install the latest versions of TensorFlow and Keras, you can use the following commands:\n",
    "\n",
    "For TensorFlow\n",
    "\n",
    "!pip install tensorflow\n",
    "\n",
    "For Keras:\n",
    "\n",
    "!pip install keras\n",
    "\n",
    "\n",
    "After installing, you can load the libraries and print their versions using the following code:\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "\n",
    "\n",
    "Make sure you have the necessary permissions to install packages and run the code in your environment.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6bc02-c366-4ef2-89d4-301d23f44fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q2.\n",
    "\n",
    "#To load the Wine Quality dataset, you can download the CSV file from the provided link and then load it into your Python environment using the Pandas library. Here's an example of how you can do it:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Explore the dimensions of the dataset\n",
    "print(\"Number of rows:\", data.shape[0])\n",
    "print(\"Number of columns:\", data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a098b393-a8c7-4d47-902b-4f73d4999206",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q3.\n",
    "\n",
    "\n",
    "To check for null values, identify categorical variables, and encode them in the Wine Quality dataset, you can use the Pandas library. Here's an example of how you can do it:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Check for null values\n",
    "print(\"Null values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Identify categorical variables\n",
    "categorical_vars = data.select_dtypes(include=[\"object\"]).columns\n",
    "print(\"Categorical variables:\")\n",
    "print(categorical_vars)\n",
    "\n",
    "# Encode categorical variables\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_vars)\n",
    "\n",
    "# Display the encoded dataset\n",
    "print(\"Encoded dataset:\")\n",
    "print(data_encoded.head())\n",
    "\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "The code above uses the isnull() function to check for null values in the dataset. The select_dtypes() function is used to identify columns with object (categorical) data types. Then, the get_dummies() function from Pandas is used to encode the categorical variables into numeric dummy variables. The encoded dataset is then displayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c27e165-7dd9-4865-90dc-d5315a3b14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q4.\n",
    "\n",
    "To separate the features and target variables from the Wine Quality dataset, you can use the Pandas library. Here's an example of how you can do it:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Display the separated variables\n",
    "print(\"Features:\")\n",
    "print(features.head())\n",
    "print(\"\\nTarget:\")\n",
    "print(target.head())\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In the code above, the drop() function is used to remove the \"quality\" column from the dataset, leaving only the features. The \"quality\" column is then assigned to the target variable. Finally, the separated features and target variables are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f918d-6edf-4e66-bf0e-856584b9c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q5.\n",
    "\n",
    "\n",
    "To perform a train-test split and divide the Wine Quality dataset into training, validation, and test datasets, you can use the scikit-learn library. Here's an example of how you can do it:\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training data into training and validation datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the dimensions of the datasets\n",
    "print(\"Training dataset shape:\", X_train.shape)\n",
    "print(\"Validation dataset shape:\", X_val.shape)\n",
    "print(\"Test dataset shape:\", X_test.shape)\n",
    "\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In the code above, the train_test_split() function from scikit-learn is used twice. Firstly, it is used to split the dataset into a training set (X_train and y_train) and a test set (X_test and y_test) with a test size of 20% of the total dataset. Then, the training set is further split into a training set (X_train and y_train) and a validation set (X_val and y_val) with a validation size of 20% of the training set. Finally, the dimensions of the resulting datasets are displayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f455232-c617-4dee-b6cf-09558e1198ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q6.\n",
    "\n",
    "To perform scaling on the Wine Quality dataset, you can use the scikit-learn library. Scaling is particularly useful when working with features that have different scales or units. Here's an example of how you can do it:\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform scaling on the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Convert the scaled features back to a DataFrame\n",
    "scaled_features_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
    "\n",
    "# Display the scaled features\n",
    "print(\"Scaled features:\")\n",
    "print(scaled_features_df.head())\n",
    "\n",
    "\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In the code above, the StandardScaler class from scikit-learn is used to perform standardization on the features. The fit_transform() method scales the features, and the resulting scaled features are stored in the scaled_features array. Then, the scaled features are converted back to a DataFrame for better visualization. Finally, the scaled features are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dd9a12-a84b-4220-bee5-ce78009f872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q7.\n",
    "\n",
    "\n",
    "To create a neural network model with at least two hidden layers and an output layer for the Wine Quality dataset, you can use the TensorFlow and Keras libraries. Here's an example of how you can define such a model:\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform scaling on the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In the code above, the Sequential model from Keras is used to create a feedforward neural network. It consists of two hidden layers with 64 and 32 units respectively, and an output layer with a single unit using the sigmoid activation function for binary classification. The model is compiled with the Adam optimizer and binary cross-entropy loss. It is then trained on the training data for 10 epochs with a batch size of 32, and the test accuracy is evaluated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd17eba3-06a8-4b60-b708-8470fc528334",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q8.\n",
    "\n",
    "Certainly! Here's an example of how you can create a Sequential model and add all the layers to it for the Wine Quality dataset:\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform scaling on the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Sequential model and add layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In this code, a Sequential model is created using keras.Sequential(). The layers are added to the model using the model.add() method. The model consists of a Dense layer with 64 units and ReLU activation as the first hidden layer, a Dense layer with 32 units and ReLU activation as the second hidden layer, and a Dense layer with 1 unit and sigmoid activation as the output layer. The model is then compiled, trained on the training data, and evaluated on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89725101-c2d7-442a-b861-08f8e456ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q9.\n",
    "\n",
    "\n",
    "To implement a TensorBoard callback to visualize and monitor the model's training process, you can use the TensorBoard callback from TensorFlow. Here's an example of how you can do it with the Wine Quality dataset:\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform scaling on the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Sequential model and add layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create a TensorBoard callback\n",
    "log_dir = \"logs/fit\"\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Train the model with the TensorBoard callback\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In this code, the TensorBoard callback from TensorFlow is imported. The log_dir variable specifies the directory where the logs for TensorBoard will be stored. The tensorboard_callback is created with the specified log directory.\n",
    "\n",
    "During the training phase, the tensorboard_callback is passed as a callback to the fit() method. This enables the model to write logs to the specified directory, which can be later visualized using TensorBoard.\n",
    "\n",
    "After training, you can launch TensorBoard by running the following command in the terminal or command prompt:\n",
    "\n",
    "tensorboard --logdir logs/fit\n",
    "\n",
    "This command starts the TensorBoard server, and you can access the TensorBoard interface by opening the provided URL in a web browser. From there, you can explore and monitor various aspects of the training process, including loss, accuracy, and more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03635296-276f-4019-aabb-fd005001b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q12.\n",
    "\n",
    "Certainly! Here's an example of how you can print the model summary for the Wine Quality dataset:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform scaling on the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Sequential model and add layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In this code, the model is defined using keras.Sequential(), and the layers are added to the model. After defining the model, you can print its summary using model.summary(). The summary provides information about the layers in the model, including the number of parameters and the output shape of each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbba37d-a6f7-49e1-97b1-af93e17c25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q11.\n",
    "\n",
    "To implement a ModelCheckpoint callback to save the best model based on a chosen metric during training, you can use the ModelCheckpoint callback from TensorFlow. Here's an example of how you can do it with the Wine Quality dataset:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform scaling on the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Sequential model and add layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\"best_model.h5\", monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Train the model with ModelCheckpoint callback\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[checkpoint_callback])\n",
    "\n",
    "# Load the best model saved by the ModelCheckpoint callback\n",
    "best_model = keras.models.load_model(\"best_model.h5\")\n",
    "\n",
    "# Evaluate the best model\n",
    "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In this code, the ModelCheckpoint callback from TensorFlow is imported. The checkpoint_callback is created with the monitor parameter set to the chosen metric to monitor, in this case, the validation loss. The save_best_only parameter is set to True, which means only the best model based on the monitored metric will be saved.\n",
    "\n",
    "During the training phase, the checkpoint_callback is passed as a callback to the fit() method. This enables the model to save the best model based on the defined criteria.\n",
    "\n",
    "After training, you can load the best model using keras.models.load_model() and evaluate its performance on the test data. The test_loss and test_acc variables store the loss and accuracy values, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ca117-a521-4ac5-af67-2aae1aebf996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Q10.\n",
    "\n",
    "\n",
    "\n",
    "To use Early Stopping to prevent overfitting by monitoring a chosen metric and stopping the training if no improvement is observed, you can use the EarlyStopping callback from TensorFlow. Here's an example of how you can implement it with the Wine Quality dataset\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform scaling on the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Sequential model and add layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create an EarlyStopping callback\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Train the model with EarlyStopping callback\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping_callback])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In this code, the EarlyStopping callback from TensorFlow is imported. The early_stopping_callback is created with the monitor parameter set to the chosen metric to monitor, in this case, the validation loss. The patience parameter is set to 3, which means training will stop if there is no improvement in the monitored metric for 3 consecutive epochs.\n",
    "\n",
    "During the training phase, the early_stopping_callback is passed as a callback to the fit() method. This enables early stopping based on the defined criteria, preventing overfitting and unnecessary training.\n",
    "\n",
    "After training, you can evaluate the model's performance on the test data as usual. The test_loss and test_acc variables store the loss and accuracy values, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77da5d06-e438-4844-ba38-15fae1227799",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q13.\n",
    "\n",
    "\n",
    "Certainly! Here's an example of how you can use binary cross-entropy as the loss function, Adam optimizer, and include the metric 'accuracy'\n",
    "\n",
    "for the Wine Quality dataset\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform scaling on the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Sequential model and add layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In this code, the model is defined using keras.Sequential(), and the layers are added to the model. The loss function is set to 'binary_crossentropy' for binary classification tasks. The optimizer is set to 'adam', which is a popular choice for many deep learning tasks. The metrics are set to ['accuracy'] to monitor the accuracy of the model during training.\n",
    "\n",
    "After defining the model, you can train it using the fit() method. The training data is provided as X_train and y_train, and the validation data is provided as X_test and y_test. The model will be trained for 100 epochs with a batch size of 32.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d645182-cfee-4a23-96c4-78cf94db147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q14.\n",
    "\n",
    "\n",
    "To compile the model with the specified loss function, optimizer, and metrics for the Wine Quality dataset, you can use the following code:\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform scaling on the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Sequential model and add layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In this code, the model is defined using keras.Sequential(), and the layers are added to the model. The loss function is set to 'binary_crossentropy' for binary classification tasks. The optimizer is set to 'adam', which is a popular choice for many deep learning tasks. The metrics are set to ['accuracy'] to monitor the accuracy of the model during training.\n",
    "\n",
    "After defining the model, you can compile it using the compile() method. The loss function, optimizer, and metrics are specified within this method. Then, you can train the model using the fit() method, providing the training data as X_train and y_train, and the validation data as X_test and y_test. The model will be trained for 100 epochs with a batch size of 32.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cfae6-e1e1-4cc0-a418-7b002a3435c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q15.\n",
    "\n",
    "\n",
    "To fit the model to the data while incorporating the TensorBoard, Early Stopping, and ModelCheckpoint callbacks, you can use the following code:\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform scaling on the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Sequential model and add layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "tensorboard_callback = TensorBoard(log_dir='./logs')\n",
    "early_stopping_callback = EarlyStopping(patience=10, monitor='val_loss')\n",
    "model_checkpoint_callback = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# Fit the model with callbacks\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test),\n",
    "          callbacks=[tensorboard_callback, early_stopping_callback, model_checkpoint_callback])\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In this code, the model is defined using keras.Sequential(), and the layers are added to the model. The loss function is set to 'binary_crossentropy' for binary classification tasks. The optimizer is set to 'adam', and the metrics are set to ['accuracy'].\n",
    "\n",
    "Callbacks are defined to incorporate TensorBoard, Early Stopping, and ModelCheckpoint functionalities. The TensorBoard callback is used to log the training and validation metrics for visualization. The EarlyStopping callback monitors the validation loss and stops the training if no improvement is observed for a certain number of epochs (10 in this case). The ModelCheckpoint callback saves the best model based on the validation loss.\n",
    "\n",
    "The model is then trained using the fit() method, and the callbacks are passed as a list to the callbacks argument. The training data is provided as X_train and y_train, and the validation data is provided as X_test and y_test. The model will be trained for a maximum of 100 epochs with a batch size of 32.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6e63c-b226-4dda-aa46-c0fc58e6543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q16.\n",
    "\n",
    "To get the model's parameters, you can use the get_weights() method of the model. This will return a list of NumPy arrays representing the weights and biases of each layer in the model. Here's an example:\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform scaling on the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Sequential model and add layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Get the model's parameters\n",
    "parameters = model.get_weights()\n",
    "\n",
    "# Print the model's parameters\n",
    "for layer in parameters:\n",
    "    print(layer.shape)\n",
    "\n",
    "    \n",
    "    Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In this code, the model is defined using keras.Sequential(), and the layers are added to the model. The model is then compiled with the specified loss function, optimizer, and metrics.\n",
    "\n",
    "After compiling the model, you can use the get_weights() method to retrieve the model's parameters. This will return a list of NumPy arrays representing the weights and biases of each layer in the model.\n",
    "\n",
    "In the provided code, the model's parameters are stored in the parameters variable, and then printed using a loop. The shape of each layer's parameters is printed to give you an idea of the dimensions of the weights and biases for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3936275f-0c02-4a1b-b0fb-5affbebd4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q17.\n",
    "\n",
    "To store the model's training history as a Pandas DataFrame, you can utilize the history attribute of the fitted model. Here's an example:\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform scaling on the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Sequential model and add layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model and get the training history\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Store the training history as a Pandas DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Print the training history\n",
    "\n",
    "\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In this code, the model is defined using keras.Sequential() and the layers are added to the model. The model is then compiled with the specified loss function, optimizer, and metrics.\n",
    "\n",
    "After compiling the model, the fit() method is called to train the model. The training history is stored in the history variable.\n",
    "\n",
    "To store the training history as a Pandas DataFrame, the history.history attribute is passed to the pd.DataFrame() function, creating a DataFrame with the training metrics for each epoch.\n",
    "\n",
    "Finally, the training history DataFrame is printed, displaying the metrics such as loss and accuracy for each epoch of training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8f63ee-9e0e-48c0-b040-d634f2b9ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q18.\n",
    "\n",
    "To plot the model's training history, you can use Matplotlib, which is a popular data visualization library in Python. Here's an example:\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "dataset_url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "data = pd.read_csv(\"winequality.csv\")\n",
    "\n",
    "# Separate the features and target variables\n",
    "features = data.drop(\"quality\", axis=1)  # Drop the \"quality\" column to get the features\n",
    "target = data[\"quality\"]  # Select the \"quality\" column as the target variable\n",
    "\n",
    "# Perform scaling on the features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Sequential model and add layers\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with specified loss function, optimizer, and metrics\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model and get the training history\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Plot the training history\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training History')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "Make sure you have downloaded the dataset from the provided link and saved it as \"winequality.csv\" in the same directory as your Python script or notebook. Adjust the file path if necessary.\n",
    "\n",
    "In this code, the model is defined using keras.Sequential() and the layers are added to the model. The model is then compiled with the specified loss function, optimizer, and metrics.\n",
    "\n",
    "After compiling the model, the fit() method is called to train the model. The training history is stored in the history variable.\n",
    "\n",
    "To plot the training history, the training loss and validation loss values are accessed from the history.history dictionary. These values are then plotted using Matplotlib. The x-axis represents the epochs, and the y-axis represents the loss. The training loss is plotted in blue, and the validation loss is plotted in orange.\n",
    "\n",
    "The plot is displayed using plt.show(). It will show the trend of the loss values over the training epochs, allowing you to visualize how the model's performance changes during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d205a-fd6a-46d8-9555-15508549beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q19.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
